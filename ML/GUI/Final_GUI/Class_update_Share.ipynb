{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import html5lib\n",
    "import time\n",
    "import sqlite3\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import yfinance as yf\n",
    "import mplfinance as mpf\n",
    "from datetime import datetime, timedelta,date\n",
    "import datetime\n",
    "import plotly\n",
    "import plotly.graph_objs as go\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import spacy\n",
    "import numpy\n",
    "from googletrans import Translator\n",
    "from geopy.geocoders import Nominatim\n",
    "from alpha_vantage.fundamentaldata import FundamentalData\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Update_Stock():\n",
    "    def __init__(self,market) :\n",
    "        self.location_db = r'C:\\Users\\Admin\\Desktop\\SOFTDEV2\\SOFTWARE-DEVELOPMENT-2\\share_V3.sqlite'\n",
    "        self.Market = str(market)\n",
    "\n",
    "    def get_symbol_id(self):\n",
    "        con = sqlite3.connect(self.location_db)\n",
    "        cur = con.cursor()\n",
    "        sql = f\"\"\"select Information.Symbol,Information.SymbolId  \n",
    "                from Information Inner join Market on Market.MarketId = Information.MarketId\n",
    "                where Market.Mname = \"{self.Market}\"\n",
    "                \"\"\"\n",
    "        cur.execute(sql)\n",
    "        records = cur.fetchall()\n",
    "        con.close()\n",
    "        symbol_id = {}\n",
    "        for share in records: symbol_id[share[0]] = share[1]\n",
    "            \n",
    "        return symbol_id\n",
    "    \n",
    "    # ดึงราคหุ้นจาก yfinance รายวัน\n",
    "    def updateData_Day(self,share):\n",
    "\n",
    "        if share in self.get_symbol_id().keys():\n",
    "            \n",
    "            start_date = self.get_max_date('Stock_price_day',self.get_symbol_id()[share]) + datetime.timedelta(days=1)\n",
    "            \n",
    "            end_date = (datetime.datetime.now()).strftime('%Y-%m-%d')\n",
    "\n",
    "            if start_date < (datetime.datetime.strptime(end_date, '%Y-%m-%d')) :\n",
    "\n",
    "                detail = yf.download(share, interval='1D', start=start_date, end=end_date)\n",
    "\n",
    "                if not(detail.empty):\n",
    "                    detail['SymbolId'] = str(int(self.get_symbol_id()[share]))\n",
    "                    table_price = detail\n",
    "                    table_price = detail.reset_index()\n",
    "\n",
    "                    return table_price\n",
    "\n",
    "        return pd.DataFrame({'Date':[],'Open':[],'High':[],'Low':[],'Close':[],'Adj Close':[],'Volume':[],'SymbolId':[]})\n",
    "    \n",
    "    # ดึงราคหุ้นจาก yfinance รายชั่วโมง\n",
    "    def updateData_hours(self,share):\n",
    "\n",
    "\n",
    "        if share in self.get_symbol_id().keys():\n",
    "            \n",
    "            max_date = self.get_max_date('Stock_price_hours',self.get_symbol_id()[share])\n",
    "            start_date =  max_date + datetime.timedelta(hours=1)\n",
    "       \n",
    "            detail = yf.download(share, interval='1h', start=start_date )\n",
    "\n",
    "            if not(detail.empty):\n",
    "\n",
    "                # In the case of Python versioin 3.10 and up, comment 2 below.\n",
    "                # detail.index = detail.index.tz_convert('Asia/Bangkok')\n",
    "                # detail.index = detail.index.tz_localize(None)\n",
    "                detail['SymbolId'] = int(self.get_symbol_id()[share])\n",
    "                table_price = detail.reset_index()\n",
    "            \n",
    "                return table_price\n",
    "          \n",
    "        return pd.DataFrame({'Datetime':[],'Open':[],'High':[],'Low':[],'Close':[],'Adj Close':[],'Volume':[],'SymbolId':[]})\n",
    "\n",
    "    # นำ dataframe มาเพิ่มลงใน database \n",
    "    def combineData(self,stock_name,table_price):\n",
    "        \n",
    "        try :\n",
    "            \n",
    "            if table_price.empty: return ''\n",
    "                \n",
    "            con = sqlite3.connect(self.location_db)\n",
    "            cur = con.cursor()\n",
    "            column = {'Stock_price_hours':'Datetime','Stock_price_day':'Date'}\n",
    "            sql = \"\"\" select * from {} where {} = \"{}\" and SymbolId = \"{}\" \"\"\".format(stock_name,column[stock_name],table_price.iloc[0][column[stock_name]],int(table_price.iloc[0]['SymbolId']))\n",
    "            cur.execute(sql)\n",
    "            con.close\n",
    "            records = cur.fetchall()\n",
    "\n",
    "            if records == []:\n",
    "\n",
    "                table_price[column[stock_name]] = pd.to_datetime(table_price[column[stock_name]], format='%Y/%m/%d %H:%M:%S')\n",
    "                # !!!!!! sensitive function !!!!!!!!!\n",
    "                # new_table = table_price.to_sql(stock_name,con,index=False,if_exists='append')\n",
    "                con.commit()\n",
    "                con.close()\n",
    "                return 'Done Update : ',table_price\n",
    "\n",
    "            else : return 'Data already in database',pd.DataFrame({'Datetime':[],'Open':[],'High':[],'Low':[],'Close':[],'Adj Close':[],'Volume':[],'SymbolId':[]})\n",
    "\n",
    "        except KeyError: return 'Table name incorrect',pd.DataFrame({'Datetime':[],'Open':[],'High':[],'Low':[],'Close':[],'Adj Close':[],'Volume':[],'SymbolId':[]})\n",
    "            \n",
    "            \n",
    "    def get_max_date(self,table,share):\n",
    "    \n",
    "        \n",
    "        try :\n",
    "            \n",
    "            con = sqlite3.connect(self.location_db)\n",
    "            cur = con.cursor()\n",
    "            \n",
    "            column = {'Stock_price_hours':'Datetime','Stock_price_day':'Date'}\n",
    "\n",
    "            sql = \"\"\"select {} From {} where SymbolId = '{}' ORDER BY {} DESC LIMIT 1;\"\"\".format(column[table],table,share,column[table])\n",
    "\n",
    "            stock_data = pd.read_sql(sql,con)\n",
    "            con.close()\n",
    "\n",
    "            stock_data[column[table]] = pd.to_datetime(stock_data[column[table]], format='%Y/%m/%d')\n",
    "\n",
    "            return max(stock_data[column[table]])\n",
    "        \n",
    "        except ValueError: \n",
    "            reverse = {'Date' : 360*50,'Datetime' : 720}\n",
    "            stock_data = pd.DataFrame(['0'],columns =[column[table]])\n",
    "            stock_data[column[table]][0] = pd.to_datetime(date.today() - timedelta(days=reverse[column[table]]), format='%Y/%m/%d %H:%M:%S')\n",
    "            return max(stock_data[f'{column[table]}'])\n",
    "\n",
    "    def UpdatePicehours(self,share):\n",
    "\n",
    "        if self.Market in ['SET','NASDAQ','CRYPTO']: return self.combineData('Stock_price_hours',self.updateData_hours(share))\n",
    "\n",
    "        else : return pd.DataFrame({'Date':[],'Title':[],'NewsId':[],'Date':[],'Title':[],'Description':[],'Img':[],'Link':[],'Source':[],'Content':[]}),{}\n",
    "\n",
    "    def UpdatePiceDays(self,share):\n",
    "\n",
    "        if self.Market in ['SET','NASDAQ','CRYPTO']: return self.combineData('Stock_price_day',self.updateData_Day(share))\n",
    "\n",
    "        else : return pd.DataFrame({'Date':[],'Title':[],'NewsId':[],'Date':[],'Title':[],'Description':[],'Img':[],'Link':[],'Source':[],'Content':[]}),{}\n",
    "        \n",
    "    # ----------------------------------------------------------- For News -----------------------------------\n",
    "\n",
    "    def KaohoonNews(self,share):\n",
    "\n",
    "        chest,I,tag_share_news  = [],0,{}\n",
    "\n",
    "        url = requests.get(f\"https://www.kaohoon.com/?s={share}\")\n",
    "        soup = BeautifulSoup(url.text, 'html')\n",
    "        for ultag in soup.find_all('ul', {'class': 'posts-items'}):\n",
    "\n",
    "            for li in ultag.find_all('li'):\n",
    "\n",
    "                df,st  = {},''\n",
    "                text = (li.text).split('\\n')\n",
    "\n",
    "                df['Date'],df['Title'],df['Description'],df['Img'],df['Link'],df['Source'] = text[3],text[4],text[5],li.find('img')['src'],li.find('a')['href'],'kaohoon'\n",
    "\n",
    "                soup = BeautifulSoup((requests.get(f\"{df['Link']}\")).text, 'html')\n",
    "\n",
    "                div = soup.find('div', {'class': 'entry-content entry clearfix'})\n",
    "\n",
    "                if str(div) == 'None' : return {}\n",
    "                for li in div.find_all('p'):\n",
    "                    text = li.text\n",
    "                    if text != '':\n",
    "                        st += li.text + '\\n'\n",
    "                \n",
    "                df['Content'] = st\n",
    "                tag_share_news[df['Title']] = []\n",
    "\n",
    "                if st != '': chest.append(df)\n",
    "                \n",
    "        return  pd.DataFrame(chest),tag_share_news\n",
    "\n",
    "    def YahooNews(self,share):\n",
    "\n",
    "        url = requests.get(f\"https://finance.yahoo.com/quote/{share}\")\n",
    "        chest,tag_share_news  = [],{}\n",
    "        soup = BeautifulSoup(url.text, 'html')\n",
    "\n",
    "        for div_all in soup.find_all('div', {'id': 'quoteNewsStream-0-Stream'}):\n",
    "\n",
    "            for li in div_all.find_all('li', {'class': 'js-stream-content Pos(r)'}):\n",
    "\n",
    "                for l in li.find_all('div', {'class': 'Py(14px) Pos(r)'}):\n",
    "\n",
    "                    df,st,share_tag  = {},'',{}\n",
    "                    \n",
    "                    tag_a = l.find('a')\n",
    "                    \n",
    "                    # Img\n",
    "                    tag_img = l.find('img')\n",
    "                    if str(tag_img) != 'None': url_img = l.find('img')['src']\n",
    "                    else : url_img = 'https://www.lifewire.com/thmb/yx5oJUJ4fA1TQ0h0pl9FM7Kc4Fo=/1500x0/filters:no_upscale():max_bytes(150000):strip_icc()/yahoo-logo-2019-879b7bed612d4bbc97065dce2a0f2d73.png'\n",
    "\n",
    "                    # Get Content -----------------------------------------------------\n",
    "                    \n",
    "                    soup_content = BeautifulSoup((requests.get('https://finance.yahoo.com/' + tag_a['href'])).text, 'html')\n",
    "\n",
    "                    for li_ in soup_content.find_all('p'):\n",
    "                        text = li_.text\n",
    "                        if text != '': st += li_.text + '\\n'\n",
    "\n",
    "                    try :        \n",
    "\n",
    "                        df['Date'],df['Title'],df['Description'],df['Img'],df['Link'],df['Source'],df['Content']  = datetime.datetime.strptime(soup_content.find('time')['datetime'], '%Y-%m-%dT%H:%M:%S.%f%z').strftime('%d/%m/%Y'),tag_a.text,l.find('p').text,url_img,'https://finance.yahoo.com/' + tag_a['href'],'yahoo',st\n",
    "                        share_news = [i.text for i in soup_content.find_all('div', {'class': 'xray-card-row-title'})]\n",
    "                        tag_share_news[df['Title']] = share_news\n",
    "                        chest.append(df)\n",
    "                    except TypeError: pass\n",
    "                        \n",
    "\n",
    "        return pd.DataFrame(chest),tag_share_news\n",
    "       \n",
    "    def get_id_News(self,title):\n",
    "        # connect to the database\n",
    "        conn,id = sqlite3.connect(self.location_db),''\n",
    "        c = conn.cursor()\n",
    "\n",
    "        # search for words in the table\n",
    "        c.execute(f\"\"\"SELECT * FROM News WHERE title=\"{title}\" \"\"\")\n",
    "        results = c.fetchall()\n",
    "        conn.close()\n",
    "\n",
    "        if results != []: return str(results[0][0])\n",
    "            \n",
    "        else : return 'None'\n",
    "\n",
    "    def Share_finder(self,words,NewsId,source):\n",
    "        # connect to the database\n",
    "        conn = sqlite3.connect(self.location_db)\n",
    "        c = conn.cursor()\n",
    "        share = []\n",
    "\n",
    "        for word in words : \n",
    "\n",
    "            w = word\n",
    "            if source == 'kaohoon': w = word + '.BK'\n",
    "\n",
    "            # search for words in the table\n",
    "            c.execute(f\"\"\"SELECT * FROM Information WHERE Symbol=\"{w}\" or Sname=\"{word}\"; \"\"\")\n",
    "            results = c.fetchall()\n",
    "\n",
    "            if results != []:\n",
    "                data = {}\n",
    "                data['SymbolId'],data['NewsId'] = results[0][0],NewsId\n",
    "                share.append(data)\n",
    "\n",
    "        # close the database connection\n",
    "        conn.close()\n",
    "\n",
    "        return share\n",
    "    \n",
    "    def End_point_FindderNews(self,chest):\n",
    "        # การใช้งานจริง เลิก comment 3 function sensitive function\n",
    "        df_news,tag = chest[0],chest[1]\n",
    "        shareNews = []\n",
    "        locaNew = []\n",
    "        column = 'Date,Title,Description,Img,Link,Source,Content'\n",
    "        data = list(df_news.itertuples(index=False, name=None))\n",
    "        tool = Update_Stock('SET')\n",
    "\n",
    "        for i in range(len(data)):\n",
    "\n",
    "            # ตรวจสอบ News ว่ามีใน database รึยัง\n",
    "            NewsId = tool.get_id_News(df_news['Title'][i])\n",
    "            print(i)\n",
    "            if NewsId == 'None':\n",
    "                pass\n",
    "                # # ถ้าไม่มีจะเพิ่ม แต่ถ้ามีจะแสดงว่าเคยดึงสถานที่กับหุ้นไปแล้วจะหยุดการทำงาน !!!!!! sensitive function !!!!!!!!!\n",
    "                # tool.InsertDB_SqlCommand('News',column,data[i])\n",
    "\n",
    "                # # # ดึง id ใหม่อีกครั้งจากหุ้นที่พึงเพิ่มเข้าไป\n",
    "                NewsId = tool.get_id_News(df_news['Title'][i])\n",
    "\n",
    "                en = Location_finder( df_news['Content'][i])\n",
    "\n",
    "                words = en.Separate_words()\n",
    "\n",
    "                words += tag[df_news['Title'][i]]\n",
    "\n",
    "                share = tool.Share_finder(words,NewsId,df_news['Source'][i])\n",
    "\n",
    "                shareNews += share\n",
    "\n",
    "                words = en.filter_special_2(words)\n",
    "\n",
    "                loca = en.find_location(words,NewsId)\n",
    "                locaNew += loca\n",
    "\n",
    "\n",
    "        locainNews = pd.DataFrame(locaNew)\n",
    "        shareinNews = pd.DataFrame(shareNews)\n",
    "\n",
    "        # !!!!!! sensitive function !!!!!!!!!\n",
    "        # tool.save_into_db('Location_in_News',locainNews)\n",
    "        # !!!!!! sensitive function !!!!!!!!!\n",
    "        # tool.save_into_db('Share_in_News',shareinNews)\n",
    "        return df_news,locainNews,shareinNews\n",
    "    \n",
    "    def UpdateNews(self,share):\n",
    "\n",
    "        if self.Market == 'SET': return self.End_point_FindderNews(self.KaohoonNews(share))\n",
    "\n",
    "        elif self.Market == 'NASDAQ' or self.Market == 'CRYPTO' : return self.End_point_FindderNews(self.YahooNews(share))\n",
    "\n",
    "        else : return pd.DataFrame({'Date':[],'Title':[],'NewsId':[],'Date':[],'Title':[],'Description':[],'Img':[],'Link':[],'Source':[],'Content':[]}),{}\n",
    " \n",
    "    # ----------------------------------------------------------- For Financial -----------------------------------\n",
    "\n",
    "    def getStockDetails(self,driver,name):\n",
    "        sections = ['stock-financial-report','stock-financial-ratio']\n",
    "        url = 'https://www.finnomena.com/stock/' + name\n",
    "        driver.get(url)\n",
    "        quarters = []\n",
    "        data = []\n",
    "        for section in sections:\n",
    "                obj = {}\n",
    "                keys = []\n",
    "                headerElements = driver.find_element(By.CSS_SELECTOR,\n",
    "            f'#{section}>div>div>div>div>div.table-overflow-wrapper>div.topic-wrapper.user-select-none.float-left.overflow-shadow')\n",
    "                for topic in headerElements.find_elements(By.CLASS_NAME,'topic')[1:]:\n",
    "                    key = BeautifulSoup(topic.get_attribute('id')).get_text()\n",
    "                    keys.append(key)\n",
    "                contentElements = driver.find_element(By.CSS_SELECTOR, \n",
    "                                    f'#{section}>div>div>div>div>div.table-overflow-wrapper>div.content-wrapper.user-select-none')\n",
    "                contentHTML = BeautifulSoup(contentElements.get_attribute('innerHTML'), 'html.parser')\n",
    "                dataWrapper = contentHTML.find_all('div', {'class': 'data-wrapper'})\n",
    "                if len(quarters) == 0:\n",
    "                    for div in contentHTML.find_all('div', {'class': 'year'}):\n",
    "                        quarters.append(div.get_text())\n",
    "                for i in range(len(dataWrapper)): \n",
    "                    values = [data.get_text() for data in dataWrapper[i].find_all('div', {'class': 'data-each'})]\n",
    "                    key = f\"{keys[i]}\"\n",
    "                    obj[key] = values\n",
    "                    data.append(obj)\n",
    "        return (quarters,data)\n",
    "\n",
    "    def getFinancialDetails(self,symbol,driver):\n",
    "        quarterlyOrAnnual,responseData = self.getStockDetails(driver,name=symbol)\n",
    "        data = {}\n",
    "        for d in responseData:\n",
    "            data = dict(list(data.items()) + list(d.items()))\n",
    "        data = {key: data[key] for key in ['Asset', 'TotalDebt', 'Equity', 'Revenue', 'NetProfit', 'ROA', 'ROE']}\n",
    "        data['Period'] = quarterlyOrAnnual\n",
    "        data['SymbolId'] = str(int(self.get_symbol_id()[symbol + '.BK']))\n",
    "        df = pd.DataFrame(data)\n",
    "        df = df.replace('', '0')\n",
    "        df = df.iloc[:-1]\n",
    "        df.iloc[:, :7] = df.iloc[:, :7].applymap(lambda x: x.replace(',', '')).astype(float)\n",
    "        df = df.replace(0.00, numpy.nan)\n",
    "        return df\n",
    "\n",
    "    def FinnomenaDetail(self,driver):\n",
    "        values = list(self.get_symbol_id().keys())\n",
    "        nameNoData = ['AURA', 'COMM', 'TRUE']\n",
    "        details = []\n",
    "        for name in values:\n",
    "\n",
    "            name = name[:-3]\n",
    "            print(name)\n",
    "            response = requests.get('https://www.finnomena.com/stock/' + name)\n",
    "            if (response.status_code == 404) or (name in nameNoData):\n",
    "                continue\n",
    "            else:\n",
    "                df = self.getFinancialDetails(driver,symbol=name)\n",
    "                details.append(df)\n",
    "        df_new = pd.concat(details)\n",
    "        return df_new\n",
    "    \n",
    "    def updateFinnomena(self,symbol,driver):\n",
    "        conn = sqlite3.connect(self.location_db)\n",
    "        df_db = pd.read_sql_query(\"\"\"SELECT Asset,TotalDebt,Equity,Revenue,NetProfit,ROA,ROE,Period,Symbol,fq.SymbolId FROM Financial_quarterly as fq INNER JOIN Information as i on i.SymbolId = fq.SymbolId\"\"\", conn)\n",
    "        if symbol in ['AURA', 'COMM', 'TRUE']:\n",
    "            return 'There is no information for this stock.'\n",
    "        else:\n",
    "            df_check = pd.read_sql_query(f\"\"\"SELECT Asset,TotalDebt,Equity,Revenue,NetProfit,ROA,ROE,Period,Symbol,fq.SymbolId FROM Financial_quarterly as fq INNER JOIN Information as i on i.SymbolId = fq.SymbolId WHERE Symbol = '{str(symbol)+'.BK'}' \"\"\", conn)\n",
    "            data_put = self.getFinancialDetails(symbol,driver).tail(1)\n",
    "            df_db = df_db.drop(columns=['Symbol'])\n",
    "            if data_put['Period'].unique() not in df_check['Period'].unique():\n",
    "                data_put.to_sql('Financial_quarterly', conn, if_exists='append', index=False)\n",
    "                conn.close()\n",
    "                return 'Update Success'\n",
    "            else:\n",
    "                return 'This data is up to date.'\n",
    "        \n",
    "    # ------------------------------------------------------------------------------------------\n",
    "    def alphaVantage_data(self,symbol):\n",
    "        apikey = '4YLKM5SFV5RXMQCG'\n",
    "        fd = FundamentalData(apikey, output_format = 'pandas')\n",
    "        balance_sheet = fd.get_balance_sheet_quarterly(symbol)\n",
    "        income_state = fd.get_income_statement_quarterly(symbol)\n",
    "        balance_sheet = balance_sheet[0].T\n",
    "        income_state = income_state[0].T\n",
    "        return (balance_sheet, income_state)\n",
    "\n",
    "    def calInfo(self,data):\n",
    "        Equity = (data['totalAssets'] - data['totalLiabilities'])\n",
    "        NetProfit = (data['grossProfit'] - data['operatingExpenses'])\n",
    "        ROA_value = (data['netIncome'] / data['totalAssets']) * 100\n",
    "        ROE_value = (data['netIncome'] / data['totalShareholderEquity']) * 100\n",
    "        data['Equity'] = Equity\n",
    "        data['NetProfit'] = NetProfit\n",
    "        data['ROA'] = ROA_value\n",
    "        data['ROE'] = ROE_value\n",
    "        return data\n",
    "    \n",
    "    def arrangeAlphaVantageDetail(self,symbol):\n",
    "        data_balance, data_income = self.alphaVantage_data(symbol)\n",
    "        result = pd.concat([data_balance, data_income])\n",
    "        result = result.T.reset_index()\n",
    "        new_result = result.loc[:,~result.columns.duplicated(keep='first')]\n",
    "        new_result = new_result.drop(new_result.columns[[0,2]], axis=1)\n",
    "        new_result['netIncome'] = result['netIncome']\n",
    "        new_result.iloc[:, 1:] = new_result.iloc[:, 1:].apply(pd.to_numeric, errors='coerce')\n",
    "        new_result = self.calInfo(new_result)\n",
    "        new_result['SymbolId'] = str(int(self.get_symbol_id()[symbol]))\n",
    "        result_after = new_result.drop(new_result.columns[[2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,19,20,21,22,23,24,25,26,27,28,29,30,\n",
    "                                            31,32,33,34,35,36,37,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60]]\n",
    "                                            , axis=1)\n",
    "        result_after = result_after.round(3)\n",
    "        result_after = result_after.rename(columns={\"fiscalDateEnding\": \"Period\", \"totalAssets\": \"Asset\", \"totalLiabilities\": \"TotalDebt\",\n",
    "                                    \"totalRevenue\": \"Revenue\"})\n",
    "        result_after = result_after[['Asset', 'TotalDebt', 'Equity', 'Revenue', 'NetProfit', 'ROA', 'ROE', 'Period', 'SymbolId']]\n",
    "        result_after['Period'] = pd.to_datetime(result_after['Period'])\n",
    "        result_after = result_after[~(result_after['Period'].isna())]\n",
    "        result_after = result_after.sort_values(by=['Period'], ascending=True).reset_index(drop=True)\n",
    "        result_after['Period'] = result_after['Period'].dt.quarter.astype(str) +'Q'+ result_after['Period'].dt.year.astype(str)\n",
    "        return result_after\n",
    "\n",
    "    def AlphaVantageDetail(self):\n",
    "        values = list(self.get_symbol_id().keys())[:50] #ต่อไป 50-100\n",
    "        nameNoData = ['ACAC', 'ACACU']\n",
    "        details_alpha = []\n",
    "        count = 0\n",
    "        for name in values:\n",
    "            if name in nameNoData:\n",
    "                continue\n",
    "            elif (count == 2):\n",
    "                time.sleep(65)\n",
    "                df = self.arrangeAlphaVantageDetail(name)\n",
    "                details_alpha.append(df)\n",
    "                count = 0\n",
    "            else:\n",
    "                df2 = self.arrangeAlphaVantageDetail(name)\n",
    "                details_alpha.append(df2)\n",
    "            count+=1\n",
    "        df_new = pd.concat(details_alpha)\n",
    "        return df_new\n",
    "\n",
    "    def updateAlphaVantage(self,symbol):\n",
    "        conn = sqlite3.connect(self.location_db)\n",
    "        df_db = pd.read_sql_query(\"\"\"SELECT Asset,TotalDebt,Equity,Revenue,NetProfit,ROA,ROE,Period,Symbol,fq.SymbolId FROM Financial_quarterly as fq INNER JOIN Information as i on i.SymbolId = fq.SymbolId ;\"\"\", conn)\n",
    "        if symbol in ['ACAC','ACACU']:\n",
    "            return 'There is no information for this stock.'\n",
    "        elif symbol not in df_db['Symbol'].unique():\n",
    "            data = self.arrangeAlphaVantageDetail(symbol)\n",
    "            df_db = df_db.drop(columns=['Symbol'])\n",
    "            df_new = pd.concat([df_db, data])\n",
    "            df_new.to_sql('Financial_quarterly', conn, if_exists='append', index=False)\n",
    "            conn.close()\n",
    "            return 'Update Success.'\n",
    "        else:\n",
    "            df_check = pd.read_sql_query(f\"\"\"SELECT Asset,TotalDebt,Equity,Revenue,NetProfit,ROA,ROE,Period,Symbol,fq.SymbolId FROM Financial_quarterly as fq INNER JOIN Information as i on i.SymbolId = fq.SymbolId WHERE Symbol = '{str(symbol)}' ;\"\"\", conn)\n",
    "            data_put = self.arrangeAlphaVantageDetail(symbol).tail(1)\n",
    "            df_db = df_db.drop(columns=['Symbol'])\n",
    "            if data_put['Period'].unique() not in df_check['Period'].unique():\n",
    "                data_put.to_sql('Financial_quarterly', conn, if_exists='append', index=False)\n",
    "                conn.close()\n",
    "                return 'Update Success.'\n",
    "            else: return 'This data is up to date.'\n",
    "                \n",
    "    def updateFinancial(self,drive,symbol):\n",
    "\n",
    "        if self.Market == 'SET': return self.updateFinnomena(symbol,drive)\n",
    "\n",
    "        elif self.Market == 'NASDAQ'  : return self.updateAlphaVantage(symbol)\n",
    "\n",
    "        else : return 'We have SET and NASDAQ.'\n",
    "       \n",
    "    # ----------------------------------------------------------- For all -----------------------------------\n",
    "    def InsertDB_SqlCommand(self,table_name, column ,data):\n",
    "\n",
    "        conn = sqlite3.connect(self.location_db)\n",
    "        c = conn.cursor()\n",
    "\n",
    "        # Create a string with placeholders for each value in the data tuple\n",
    "        placeholders = \",\".join([\"?\" for _ in data])\n",
    "\n",
    "        # Construct the SQL query string\n",
    "        query_string = f\"INSERT INTO {table_name} ({column}) VALUES ({placeholders})\"\n",
    "\n",
    "        # Execute the query and commit the changes\n",
    "        c.execute(query_string, data)\n",
    "        conn.commit()\n",
    "\n",
    "        # Close the connection\n",
    "        conn.close()\n",
    "\n",
    "        return 'Succes to add {}'\n",
    "\n",
    "    def InsertDB_Pandas(self,table,dic):\n",
    "\n",
    "        df = pd.DataFrame(dic)\n",
    "        con = sqlite3.connect(self.location_db)\n",
    "        cur = con.cursor()    \n",
    "        newshare = df.to_sql(table,con,if_exists='append', index=False)\n",
    "        con.commit()\n",
    "        con.close\n",
    "\n",
    "class Location_finder():\n",
    "\n",
    "    def __init__(self,text) :\n",
    "        \n",
    "        self.text = self.translate_text(text)\n",
    "\n",
    "    def translate_text(self,text):\n",
    "\n",
    "        detector = Translator()\n",
    "\n",
    "        dec_lan = ''\n",
    "        for sec in range(int(len(text)/1000)+1):\n",
    "\n",
    "            dec_lan += detector.translate(text[1000*sec:1000*(sec+1)],des='en').text\n",
    "\n",
    "        return dec_lan\n",
    "\n",
    "    def Separate_words(self):\n",
    "\n",
    "        w = self.text.split(r'\\n')\n",
    "        for content in w : self.text += content + ' '\n",
    "\n",
    "        nlp = spacy.load('en_core_web_sm')\n",
    "        # nlp = en_core_web_sm.load()\n",
    "        doc = nlp(self.text)\n",
    "\n",
    "        word = []\n",
    "\n",
    "        for token in doc.ents:\n",
    "            \n",
    "            if token.label_ != 'DATE' and token.label_ !='CARDINAL' and token.label_ !='TIME':\n",
    "                # print(token.text,token.label_)     \n",
    "                word += token.text.split('\"')\n",
    "\n",
    "        return list(numpy.unique(word))\n",
    "    \n",
    "    def filter_special_2(self,words):\n",
    "    # Define regular expression pattern to match words\n",
    "        word_filter = []\n",
    "\n",
    "        # Find all matches of the pattern in the text\n",
    "        for word in words :\n",
    "            s = 0\n",
    "            for ch in word:\n",
    "\n",
    "                if isinstance(ch , str) and ch.isnumeric(): s = 1\n",
    "\n",
    "            if s == 0: word_filter.append(word)\n",
    "                    \n",
    "        return list(numpy.unique(word_filter))\n",
    "\n",
    "    def find_location(self,words,NewsId):\n",
    "\n",
    "        geolocator = Nominatim(user_agent=\"Geolocation\")\n",
    "        loca,extra = [],[]\n",
    "        for i in words :\n",
    "    \n",
    "            location = geolocator.geocode(f\"{i}\", exactly_one=True, namedetails=True, addressdetails=True,timeout=12000, language='en')\n",
    "\n",
    "            if str(location) != 'None' :\n",
    "\n",
    "                data = {}\n",
    "\n",
    "                try :\n",
    "                    if i in ['Africa', 'Europe', 'Asia', 'North America', 'South America', 'Antarctica', 'Australia','South Pole','North pole'] :\n",
    "                        data['Lname'],data['Country'],data['Latitude'],data['Longitude'],data['NewsId'] = i,'',location.latitude, location.longitude,NewsId\n",
    "                    else:\n",
    "                        data['Lname'],data['Country'],data['Latitude'],data['Longitude'],data['NewsId'] = i,location.raw['address']['country'],location.latitude, location.longitude,NewsId\n",
    "\n",
    "                    loca.append(data)\n",
    "\n",
    "                except KeyError: extra.append(i)\n",
    "                    \n",
    "        return loca"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------------------------------Pice----------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    }
   ],
   "source": [
    "text,df = Update_Stock('SET').UpdatePicehours('EE.BK')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    }
   ],
   "source": [
    "text,df = Update_Stock('NASDAQ').UpdatePicehours('AAPL')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    }
   ],
   "source": [
    "text,df = Update_Stock('SET').UpdatePiceDays('EE.BK')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    }
   ],
   "source": [
    "text,df = Update_Stock('NASDAQ').UpdatePiceDays('AAPL')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------------------------------------------------NEWS---------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "News,locaN,shareN = Update_Stock('SET').UpdateNews('EE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_news,loca,share = Update_Stock('NASDAQ').UpdateNews('AAPL')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------------------------------------Financial------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_9556\\1693327171.py:3: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver = webdriver.Chrome(r\"C:\\Users\\Admin\\Desktop\\SOFTDEV2\\SOFTWARE-DEVELOPMENT-2\\ML\\Data\\chromedriver.exe\")\n"
     ]
    }
   ],
   "source": [
    "chrome_options = webdriver.ChromeOptions()\n",
    "chrome_options.add_argument('--no-sandbox')\n",
    "driver = webdriver.Chrome(r\"C:\\Users\\Admin\\Desktop\\SOFTDEV2\\SOFTWARE-DEVELOPMENT-2\\ML\\Data\\chromedriver.exe\")\n",
    "driver.implicitly_wait(30)\n",
    "\n",
    "def login():\n",
    "    try:\n",
    "        driver.get('https://www.finnomena.com/finno-login/')\n",
    "        time.sleep(1)\n",
    "        driver.find_element(By.NAME,'email').send_keys('bungaern2545@gmail.com')\n",
    "        driver.find_element(By.CLASS_NAME,'custom-button').click()\n",
    "        driver.find_element(By.NAME,'current_password').send_keys('tiwtiwtiw2545')\n",
    "        driver.find_element(By.CLASS_NAME,'custom-button').click()\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\JourneyQ\\AppData\\Local\\Temp\\ipykernel_14548\\3256883488.py:348: FutureWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  df.iloc[:, :7] = df.iloc[:, :7].applymap(lambda x: x.replace(',', '')).astype(float)\n"
     ]
    }
   ],
   "source": [
    "df = Update_Stock('SET').updateFinancial(driver,'EE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
